\vspace{-0.1in}
\section{Switchless Architecture}
\label{sec:arch}

The switchless architecture, as the name implies, removes switches from the data center network architecture.  Instead, switches are integrated into servers and the topology is chosen to keep the fanout of the in-server switches low.  The in-server switches could be implemented as separate boards attach to the server's I/O bus or they could be directly integrated with the processor on die.  We choose to focus on integrating the switches with the processor on die since silicon area is cheap and the latency from the processor to the switch is lower (and we are computer architects!).  In the following subsections, we discuss switchless network topologies, the design of in-server switches, the switchless network stack, and the benefits that come with the switchless architecture.

\subsection{Switchless Network Topologies}

We focus on two switchless network topologies, torus and cube.  The torus topology, Figure~\ref{fig:switchless_arch_torus}, is a two-dimensional topology where nodes are placed in a two-dimensional grid and are connected in all directions (north, south, east, and west).  Nodes at the edges have links that wrap around to the node at the opposite edge.  This creates a mesh fabric of nodes.  The cube topology, Figure~\ref{fig:switchless_arch_cube}, is similar to the torus topology with one additional dimension.  Nodes are placed into a three-dimensional grid and are also connected in all directions.  The cube topology with the same number of nodes as a given torus topology has higher bandwidth and lower average latency since nodes have more neighbors and the maximum hop count is lower.  Both of these topology limit the fanout of the in-server switch to four or six ports.

One consideration when designing a data center network topology is wiring complexity.  While complex wiring is not a fundamental problem, it can affect the time and cost to setup the data center as well as the link length.  There is a tradeoff between bandwidth and cost of a link when considering link length.  Longer links are required to either be lower bandwidth or require a different link.  The bandwidth requirement of long links can be met by using thicker cabling or different cable technologies, such as optical links.  These links, however, are more expensive[CITE and REF cost section].

The cube topology actually maps well to a data center as far as wiring goes.  If racks are arranged in a two-dimensional grid, you can think of each layer of nodes in the racks as a torus.  A cube can be created by connecting the tori vertically.  Thus, the wiring is rather trivial.  A torus topology does not map as well to the data center, so the wiring may be more complex.  However, as mentioned earlier, this problem is not fundamental and can be solved.

\begin{figure}
    \centering
    \subfloat[Torus]
    {
        \includegraphics[width=0.2\textwidth]{switchless-arch-torus}
        \label{fig:switchless_arch_torus}
    }
    \\
    \vspace{-0.05in}
    \subfloat[Cube]
    {
        \includegraphics[width=0.25\textwidth]{switchless-arch-cube}
        \label{fig:switchless_arch_cube}
    }
    \vspace{-0.07in}
    \caption{Switchless Data Center Network Topologies}
    \label{fig:switchless_topos}
\end{figure}

\subsection{In-Server Switch Design}

We focus on integrating the switch with the processor on die.  As was mentioned previously, this is beneficial because silicon area is cheap and the latency from the processor to the switch is lower.  The switch can be connected to the processor through the I/O bus or the network on chip (or any other interconnect architecture), as shown in Figure~\ref{fig:in_server_switch_design}.  In either case, the processor and switch can communicate through memory-mapped I/O.  

As for the in-server switch itself, it can be implemented either as custom logic or a general-purpose dedicated core.  Custom logic, which essentially acts as an accelerator, is higher performance and more energy efficient, however, a general-purpose dedicated core is more simple and flexible.  A general-purpose dedicated core may also be more desirable for Software Defined Networking (SDN)[CITE], where the routing protocol can be configured based on the application and network conditions [IS THIS SDN??].  Both designs are acceptable and there is no defining factor which makes one superior to the other.

\begin{figure}
    \centering
    \subfloat[Bus Based Design]
    {
        \includegraphics[width=0.2\textwidth]{in-server-switch-bus}
        \label{fig:in_server_bus}
    }
    ~
    \subfloat[Network on Chip Design]
    {
        \includegraphics[width=0.2\textwidth]{in-server-switch-noc}
        \label{fig:in_server_noc}
    }
    \vspace{-0.07in}
    \caption{In-Server Switch Processor Integration}
    \label{fig:in_server_switch_design}
\end{figure}

\subsection{Switchless Network Stack}

The switchless network topologies enable the use of a simpler network protocol stack.  We believe that IP is rather heavyweight for internal routing in a data center, especially for statically configured geometrical topologies like the switchless topologies we consider.  Thus, we propose using dimension ordered routing~\cite{Ni:1993:SWRTDN} for the torus and cube topologies.  In dimension ordered routing, all nodes are assigned an address, generally based on the location within the topology (i.e. (X, Y, Z) for cube), and is statically configured with this address.  Thus, a switch knows that sending out one interface increases in the X direction and sending out another interface decreases in the X direction.  The same is true for all dimensions.  Which interfaces point in which direction must be statically configured.  

When a switch receives a packet, it simply compares the destination address to its assigned address and determines whether the packet is destined for the local node or must be forwarded out an interface to a neighbor which advances it towards the destination node.  The interface to forward a packet over can be determined by comparing the destination address dimensions with the local address dimensions.  In dimension ordered routing, dimensions are given priority.  For example, route in the X direction until it reaches the correct X position, then route in the Y direction, then the Z direction.

This protocol is much more lightweight than IP, and does not require the Address Resolution Protocol (ARP) in order to function (which is also heavyweight, requiring lots of communication).  Routing decisions can be made quicker and the paths packets take will be no longer than the paths IP would select.  The protocol could also be improved to do adaptive routing, which enables routing based on network congestion and routing around network failures.  

In addition to replacing IP with dimension ordered routing, we would also advocate the use of wormhole routing over the traditional store-and-forward routing~\cite{Ni:1993:SWRTDN}.  In store-and-forward routing, a routing decision is not made until the entire packet has been received.  The packet is buffered until the full payload has been received.  In wormhole routing, a routing decision is made as soon as the header has been received.  Wormhole routing is more efficient because it reduces the packet latency since each router does not have to buffer the entire packet~\cite{Boppana:1995:FTWRAMN,Dally:1987:DFMRMIN,Ni:1993:SWRTDN}.  When using wormhole routing, however, care must be taken to ensure the network is deadlock-free.  The prioritization of routing in different dimensions in dimension ordered routing ensures no cycles can occur and provides a deadlock-free guarantee~\cite{Ni:1993:SWRTDN}.  Wormhole routing may require modifications to both the link layer protocol and the network level protocol.  Unfortunately, due to time constraints, we were unable to explore the use of wormhole routing in our evaluation.

Higher levels of the network stack can remain seamlessly the same.  TCP and UDP can both be implemented on top of dimension ordered routing, providing their corresponding guarantees and exposing the same interface to the applications. In addition to the switchless network stack being simpler and higher performance, it is also more amenable to integrating a switch with the processor on die since its silicon area will be smaller due to the simplicity of routing decisions.

\subsection{Benefits}

There are many benefits to the switchless architecture.  These include cost, flexibility, reliability, and potential performance improvements.  

The cost of a switchless data center is much lower than that of today's common network architectures, due to the lack of large, expensive switches.  The cost of integrating the switch on die with the processor is low because of the availability of silicon area.  Even integrating the switch as a separately attached board is cheaper.  The fundamental reason as to why switchless is cheaper is due to the lower switch fanout requirements.  This is explored further in Section~\ref{sec:cost_model}.

The switchless architecture is more flexible since adding or removing a node is trivial and the design is more amenable to new networking concepts like SDN.  Adding a node never requires purchasing another large expensive switch to which you may only connect that single node.  In the switchless architecture, to add a node one simply modifies the wiring slightly and configures the topological address.  Removing a node simply requires unplugging it from the network.  Also, the fact that the switch is integrated with the server means applications can easily modify routing protocols for SDN.  It does not require traversing the network to reach to a special switch which supports SDN.

The switchless topologies provide a very large number of routes to get from a source node to a destination node (much more than fat-tree), providing high reliability.  If a server or link goes down, an adaptive routing protocol can easily route around it.  The chance of a large network partition is very low.  In addition, in the case of congestion, packets can take different routes than they normally would.  The high availability of routes provides very nice reliability guarantees.

The switchless architecture potentially has higher performance for certain applications.  The availability of bandwidth and ease of localized communication can increase performance on applications which require it.  Integrating the switch into the server means there is a lower latency from the processor to the switch and vice versa.  Wormhole routing can also reduce packet latency.  If an adaptive routing algorithm is used, routing around congestion can also provide performance improvements.  However, the number of hops between certain nodes can be worse in the switchless architecture.  The maximum hop count in the common 3-level hierarchical topologies is 6, while the maximum hop count in a torus or cube is the sum of the number of nodes in each dimension divided by two.  Thus the max hop count for switchless topologies is potentially much higher than that of common hierarchical topologies and scales with the number of nodes in the data center.  The performance benefits are evaluated in Section~\ref{sec:eval}.
